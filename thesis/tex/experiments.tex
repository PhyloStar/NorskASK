
\section{Preprocessing}

The data files in the ASK corpus are in XML format, and contain information
about tags, mistakes and corrections, paragraphs, sentences and more. These
files were transformed into other formats during the process. First, they
were converted to plain text files stripped of all tags or correction labels,
with one sentence per line consisting of space-separated tokens, and an empty
line separating paragraphs.

These raw text files were then sent through the UDPipe pipeline for tagging
and dependency parsing. The output from UDPipe is in the CoNLL file format
with a single token per line. UDPipe tags the documents using the UD tagset,
while the original tags in the XML documents are from the Oslo-Bergen
tagger's own tagset.

\section{Baseline}

Two different sets of classes are used in the experiments. The original seven
CEFR labels, and a collapsed set where the intermediate classes such as
"A2/B1" are rounded up to the nearest canonical class. This results in only
four different labels.

The majority class in the training set is B1. A majority classifier gets an
accuracy of 18.7\% on the test set using non-collapsed labels. With the
collapsed labels, the majority class is still B1, and the accuracy on the
test set is 34.1\%.

Moving to a simple bag-of-words model, a logistic regression classifier
achieves an accuracy of 28.5\% on the dev set without collapsed labels and
58.5\% with collapsed labels. There are approximately 18,300 different word
forms in the training set.

Several neural network models were attempted as well, with input either being
word counts, character n-grams (n in the interval [2, 4], only the 10000 most
common features used), or part of speech n-grams (n in the interval [2, 4]).

All results are seen in table \ref{baseline-accuracies}.

\begin{table}
  \centering
  \begin{tabular}{lrr}
    \toprule
    Model            & All labels & Collapsed labels \\
    \midrule
    Majority         &     18.7\% &           34.1\% \\
    LogReg BOW       &     28.5\% &           58.5\% \\
    LogReg TL+Length &     43.9\% &           ------ \\
    MLP BOW          &     31.7\% &           63.4\% \\
    MLP Char         &     44.7\% &           68.3\% \\
    MLP POS          &     34.1\% &           65.0\% \\
    \bottomrule
  \end{tabular}
  \caption{Accuracy of different classifiers}
  \label{baseline-accuracies}
\end{table}

A logistic regression classifier was able to predict the CEFR score with
43.9\% accuracy using only two features: The length of the document, in
number of tokens, and the test level (IL test or AL test).

A convolutional neural network based on the architecture in
\textcite{zhang2017sensitivity} achieved an accuracy of 42.3\% using
sequences of POS tags as input to an initial embedding layer.
