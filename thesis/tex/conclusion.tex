\chapter{Conclusion} \label{ch:conclusion}

We have presented the first results for the \ac{AES} task on the ASK corpus
of Norwegian learner language. We have explored a wide variety of classifier
architectures, including linear models, simple neural networks (\acp{MLP})
and more specialized neural architectures: \acp{CNN} and \acp{RNN}. For this
dataset, we found that regression gave better results than nominal
classification.

We showed that different evaluation metrics commonly used have a complex
relationship with each other, and that the most suitable metric to use may
depend on the setting.


\section{Ethical considerations}

Language testing is a high-stakes setting. Often, an official language
proficiency certificate is needed in order to be admitted to a study
programme or gain employment, for instance. The high stakes involved means
that the grading of a language test should ideally be transparent and
explainable, something many modern machine learning based models struggle to
achieve. In the worst case, a person may fail an official language test that
is graded automatically, and have no way to know what aspects of the test
caused them to fail.

Even if a computer essay grading system is not used for grading an official
test, it may indirectly influence a language learner's decision to take a
test at a certain time. As established, language testing can be inconvenient
for those taking it, since they have to get to the testing location, pay a
fee, etc. For instance, if a language learner uses an automatic grading
system to find out what CEFR level they are at, and it concludes that they
are at a B2 level, while in fact the learner is still at a lower level, they
may choose to take a B2 level language test they are likely to fail. On the
other hand, if the grading system undershoots, the learner may waste time by
not taking the test at a point in time where they would already be ready for
it.

Language testing is in some places a requirement for gaining citizenship, a
practice that has faced scholarly criticism, for instance by
\textcite[162]{weberhorner}, who argue that language testing policies are a
means of social exclusion, rather than an opportunity that encourages
transnationals and migrants to learn the dominant language in the region they
have moved to. The practice has also been criticized for its application of
the \ac{CEFR}. For instance, \textcite{van2009fortress} finds it curious that
the required CEFR level varies between countries that use it for language
testing for citizenship, arguing that the variation reveals the practice as
arbitrary.

Native language identification also raises ethical concerns. In some cases,
authorities perform language testing of people in order to determine their
place or country of origin, a practice called \ac{LADO}. Place of origin may
in some cases be critical for the outcome of an application
for asylum or similar. The assumptions that form the basis of this practice
can be questioned. If automatic native language identification technologies
are easily accessible they may increase the occurrence of this practice. This
needs better references, but here's
\href{https://en.wikipedia.org/wiki/Language_analysis_for_the_determination_of_origin}{Wikipedia
on \ac{LADO}}.


\section{Future work}

\begin{enumerate}
    \item Ordinal regression. In theory the most natural representation of the
          problem, but architectures are not commonly available. May not be
          appropriate for all datasets. For instance, some \ac{AES} datasets
          have target scores that span a big interval.
    \item Compare model errors with annotated errors
    \item Hierarchical RNN sentence level -> document level
\end{enumerate}
